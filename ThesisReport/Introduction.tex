\chapter{Introduction}
\label{chap:Introduction}

Augmented reality (AR) systems combine standard video inputs with computer-generated objects and
usually provide real-time interaction for the users. 
In general, an augmented reality system can be defined with the following properties \cite{azuma01} :
\begin{itemize}
\item Combination of real and virtual environment
\item Registration (alignment) of real and virtual objects
\item Real-time interaction
\end{itemize}
This concept was pioneered in the 1960s by an American computer scientist named Ivan Sutherland
who created the first head-mounted augmented reality
system with the help of one of his students \cite{azuma01}.

Combining virtual objects and annotations with real
world scenes has proved to be an effective way of conveying information about the surrounding environment to
the user and can be useful in many applications such as gaming, medical surgeries, tourism, and other entertaining, informative or instructional tasks.

Many mobile augmented reality systems have been built over the past decades, from touring machine in 1997 \cite{fei97} 
to google AR glasses which was announced in 2013 \cite{google}; however, most of these prototypes have remained experimental
due to certain difficulties and constraints of using them in practical applications \cite{dras96,liv05}. To name some of the most important constraints
we can refer to:
\begin{enumerate}
\item The requirement of having more advanced hardware and technology
\item Human factors in augmented reality 
\item High demand of computational resources in order to provide a real-time interaction between the user and the system
\end{enumerate}

AR systems overlay 2D or 3D virtual objects on real scenes. Therefore, depending on the application, certain accuracy is required for 
registration of virtual and real objects. There are different approaches to obtain user's location and the position of other objects in the environment.
Tracking sensors such as gyroscope and accelerometer along with video sensors can provide information on the user's position and viewing orientation \cite{azum01}.
In order to find the position of the objects in the scene, a depth map of the surrounding environment at each time would be required. To obtain the depth of the 
objects in the scene several depth sensing technologies can be used such as 3D laser scanner, depth cameras or regular cameras. However, in order to have a mobile AR
system that is easy to carry around, the weight of the whole system will be more of a concern, hence, 3D laser scanners and depth cameras are not good choices for such systems.
Depth cameras, such as Kinect, or DS325 have certain limitation in viewing range (1m-5m) which can worsen in outdoor environments due to various types of noise. 
On the other hand, 3D laser scanners can
generate very accurate depth maps, but they are normally expensive and their price would range from 500\$ to 50,000\$. Therefore, among all these technologies, using several 
cameras to generate a depth map of the surrounding environment seems to be a more efficient approach for outdoor mobile augmented reality systems. {\newline}
However, using several cameras to get the depth map of the scene requires certain conditions to be met, geometrically and computationally. Many researchers have already looked into
this particular problem, i.e, finding the 3D position of the points in the scene from two or multiple views using regular cameras \cite{sze11}. Attempts of these researchers have resulted in
certain techniques in computer vision to find the depth of different points in an environment using one or more stereo pairs taken from slightly different points of view of the same scene.
These techniques are known as {\it Stereo Correspondence} or {\it Stereo Matching} in computer vision \cite{sze11}. Stereo matching has been one of the most studied subjects in computer vision for 
many years now and there are many solutions proposed by researchers to address this problem using different techniques; however, finding the corresponding pixels in stereo pairs with certain level of 
accuracy and in real-time for practical applications still remains a challenging task. {\newline}

% Motivation - Objective - Contributions %
\section {Research Objective}

Our motivation in this research is to study the possibility and usability of combining stereo vision approaches with AR systems considering the most important constraints that AR systems
normally come across. Therefore, we have tried to propose an evaluation scheme that enables us to examine whether using stereo vision
for obtaining 3D position of objects is potentially a practical approach in an augmented reality application. A particular application that we have been considered in
this study, is a 3D mobile augmented reality system in urban settings. 
In fact, our fundamental research question is: \newline

\begin{quote}
\textbf{"Can combination of stereo matching techniques with augmented reality meet the requirements of an AR system?"} \newline
\end{quote}

In order to find the answer to this question, some other questions are raised:
\begin{quote}
\textbf {"How does the human visual system perceive depth?"}\newline
\textbf {"What is the standard angular disparity for human visual system? How would it affect an AR system?"} \newline
\textbf {"How can we evaluate stereo vision in an augmented reality framework? What are the important factors we need to consider for 
	this type of evaluation?"} \newline
\textbf {"In a combination of augmented reality with stereo vision, what is considered as \textbf{\textit {accurate}} depth result?"} \newline
\textbf {"How a three dimensional model can be built from stereo images in computer vision?"}\newline
\textbf {"What are the requirements to maintain an interactive augmented reality application for the user"} \newline
\end{quote}

In order to pursue our goal in this research, we have designed and implemented a testbed for evaluation of
stereo matching solutions based on specific criteria which will be thoroughly described later in this report.


In the AR system of our interest, the depth map generated from two or multiple camera views will be used as the depth source to determine the position of the objects in the scene when
overlaying virtual objects at different locations and depth levels in the real environment. For our research, we decided to narrow down our study to the effect of using stereo vision
on two of the most important constraints of an AR system mentioned earlier; {\it human factors} and {\it real-time interaction}. {\newline}
Human perception of depth can vary depending on the environment and under different circumstances. Many studies have focused on the evaluation of human perception of depth within different frameworks
and in different applications, such as virtual reality, and augmented reality which have recently attracted more attention \cite{wann95,dras96,liv05,jer05,swa07,kru10}.
These studies show that the viewer perception of depth
is inversely proportional to his/her distance from the object \cite{kru10,swa07,jer05,liv05}. For instance, in \cite{swa07} some experiments are designed to study and evaluate human
perception of distance, which is the absolute depth of the objects from the observer, for an outdoor augmented reality application in urban settings. 
However, what we are more interested in for this research, is the human perception of relative depth in stereo vision, which is the ability to perceive and distinguish 
the depth of different objects relative to each other. This is known as {\it Stereoscopic Acuity} in binocular vision, which is the smallest depth difference between two points 
that can be detected in binocular vision \cite{pfa2000}. More detail about
this metric will be provided in the following chapters.
Therefore, we have investigated standard stereoacuity in human visual system and applied it to our evaluation in order to obtain the smallest detectable depth of 
objects in human binocular vision based on their distance from the observer.

Moreover, providing real-time interaction in an AR system for the user requires the processing time and update rate of the whole system to keep up ideally with the standard video frame rate, 
between 24fps and 
30fps, or higher. 
However, studies show that in practice to build a reasonable interactive augmented world the processing rate should not be less than half of the video frame rate \cite{hertz00}. 
There are different approaches to speed up a system. Acceleration of a system is possible in two ways:
\begin{enumerate}
\item Using more advanced technology and hardware
\item More sophisticated and efficient software design
\end{enumerate}
However, having access to advanced technology and better hardware is not always feasible and even the most advanced technology have some limitation in their memory space and computational capability
which may not meet the requirement for some real-time applications. 
Therefore, we have decided to focus more on the second approach while designing our evaluation system which also looks into the 3rd most important property of
an AR system mentioned earlier, i.e, real-time user interaction. \newline 

One of the most important features that makes our evaluation unique and different from the others is that we have tailored the evaluation process of stereo matching algorithms for an augmented 
reality system. Therefore, we have designed our evaluation testbed within this framework, while keeping in mind the most important properties and constrains of an AR system.
In order to address the speed factor in augmented reality systems we have decided to focus on certain regions of the scene rather than the whole image for generation and evaluation of 
depth values.  
This idea which originates from having a more efficient design for gaining speed up, 
also addresses the computational resources used during the process and may lead to significant system speed up.
It is also known that distinctive features such as {\it edges}, either in RGB or depth images from a scene, play an important role in many computer vision applications, such as object detection and 
tracking, determination of a set of reliable correspondences to build a 3D model that helps with better perception of object locations in 3D space \cite{mart01,sze11}.

Therefore, in an augmented reality application, wrong depth results, especially in those regions, which will lead to erroneous registration of virtual and real objects, 
can be perceived and picked out easier by the human eyes. This may cause poor performance of the system and possibly faulty interaction between 
the user and the augmented world. 
Hence, in this research we have focused more on studying and evaluating the results of stereo correspondence algorithms in particular regions. Since the depth of the objects 
in a scene and their perception by human visual system are more important in the AR application of our interest, we have 
defined these regions to be depth edges and their surrounding region in the scene \cite{liv05,kru10}.
Our hypothesis is that edges, which can also be good indicators of object boundaries and occlusion, are one of the important depth cues for the observer 
to perceive the depth of different objects in the scene \cite{sze11}. 
Moreover, inspection of the regions within a few pixels of the depth edges in the scene would also address the problem of occlusion and depth discontinuity, which are two of
the most challenging regions in stereo matching algorithms \cite{sch02}.
Finding correct depth values in these 
regions can lead to a more accurate combination of virtual and real objects in the scene and therefore a more reasonable augmented world from the user point of view to interact with. \newline
\newline

Since our objective in this research is to study a hybrid system of stereo vision and augmented reality, we have surveyed some of the existing approaches in stereo matching and the
related geometry of 3D reconstruction from stereo pairs. We will go through these concepts and the related works in the field more in the next chapter. 

To evaluate our proposition in this research, we have decided to assess two stereo matching algorithms. These algorithms are:
\begin{enumerate}
\item Semi-global block matching
\item On building an accurate stereo matching system on graphics hardware \cite{mei11}
\end{enumerate}

The first algorithm, also known as SGBM, is a modified version of Semi-global block matching by Hirschmuller \cite{hir08}, 
and has been implemented in Open Source Computer Vision Library (OpenCV) \cite{sgbm}. Therefore, we have used its OpenCV implementation. 
On the other hand, there was no source code available for the second algorithm. For this reason, we have used our own implementation of this solution in the evaluation process, both on CPU and GPU.

The reason we have chosen these two algorithms is that the first method, SGBM, has shown to generate acceptable results within 1-2 seconds on typical test images \cite{hir08} and 
its implementation in OpenCV library has also made its usage more common and easier in applications. The second algorithm, also known as ADCensus \cite{mei11}, was chosen since 
it has been designed in a way that
can be ported to graphics processing unit (GPU) for acceleration and according to the Middlebury evaluation benchmark \cite{mideval}, it is currently ranked as one of the top algorithms for 
stereo matching regardless of the running time.
It should also be noted that this solution uses better and more sophisticated approaches to do stereo matching which makes it superior to many other solutions \cite{mideval}. \newline
For our evaluation, we have used KITTI stereo training dataset as our stereo image data \cite{kitti}. 
Images in this dataset are more realistic since they have been taken from outdoor scenes under different circumstances 
and the ground truth disparity map is also provided for each of them, which is useful in the evaluation process. KITTI Vision project also provides a benchmark and an evaluation table
for different stereo
matching algorithms assessed in real outdoor scenes which makes it more relevant and applicable to an augmented reality application. 
AdCensus does not currently exist in the KITTI evaluation table which is another reason for us to use it in our evaluation.
