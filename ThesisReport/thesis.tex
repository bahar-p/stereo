\documentclass[dvips,letterpaper,12pt]{report}
\usepackage[square,numbers]{natbib}
\usepackage{url}
\usepackage{thesis}
\begin{document}
\chapter{Introduction}

Augmented reality (AR) systems combine standard video inputs with computer-generated objects and
usually provide real-time interaction for the users. Combining virtual objects and annotations with real
world scenes has proved to be an effective way of conveying information about the surrounding environment to
the user and can be useful in many applications such as gaming industry, medical surgeries, tourism and etc.

Many mobile augmented reality systems have been built over the past decades, from touring machine in 1997 \cite{fei97} 
to google AR glasses which was announced in 2013 \cite{google}; however most of these prototypes remained as laboratory prototypes
due to certain difficulties and constraints of using them in practical applications. To name some of the most important constraints
we can refer to \cite{liv05}:
\begin{enumerate}
\item The requirement of having more advanced hardware and technology
\item Human factors in augmented reality 
\item Optimization of computational resources inorder to provide a real-time interaction between user and the system
\end{enumerate}

AR systems overlay 2D or 3D virtual objects over real scenes. Therefore, depending on the application usage, certain accuracy would be required for 
registeration of virtual and real objects. There are different approaches to obtain user's location and the position of other objects in the environment.
Tracking sensors such as gyroscope and accelerometer along with video sensors can provide information on the user's position and viewing orientation \cite{azum01}.
In order to find the position of the objects in the scene, a depth map of the surrounding environment at each time would be required. To obtain the depth of the 
objects in the scene several depth sensing technologies can be used such as 3D laser scanner, depth cameras or regular cameras. However, in order to have a mobile AR
system that is easy to carry around, the weight of the whole system will be more of a concern, hence, 3D laser scanners and depth cameras are not good choices for such systems.
Depth cameras such as Kinect or DS325 have certain limitation in viewing range (1m-5m) which would get worse in outdoor environments. On the other hand, 3D laser scanners can
generate very accurate depth maps, but they are normally expensive and their price would range from 500\$ to 50,000\$. Therefore, among all these technologies, using several 
cameras to generate a depth map of the surrounding environment seems to be a more efficient approach for outdoor 3D mobile augmented reality systems. {\newline}
However, using several cameras to get the depth map of the scene requires certain conditions to be met, geometrically and computationally. However, many researchers have already looked into
this particular problem, i.e, finding the 3D position of the points in the scene from two or multiple views using regular cameras. The effort of these researchers have resulted in
certain techniques in computer vision to find the depth of different points in an environment using one or more stereo pairs taken from slightly different points of view of the same scene.
These techniques are known as {\it Stereo Correspondence} or {\it Stereo Matching} \cite{sze11} in computer vision. Stereo matching has been one of the most sutdied subjects in computer vision for 
many years now and there are many solutions proposed by researchers to address this problem using different techniques; however, finding the corresponding pixels in stereo pairs with certain level of 
accuracy and in real-time for practical applications still remains a challenging task. {\newline}

Our motivation in this research is to study the possibility and usability of combining stereo vision approaches with AR systems considering the important constraints that AR systems come across, 
in order to see if stereo vision 
is potentially a good approach for obtaining 3D position of objects in an augmented reality application. The particular application that we are interested in for
our study is a 3D mobile augmented reality system in urban settings. In order to pursue our goal for this research, we have designed and implemented a testbed for evaluation of
stereo matching solutions based on specific criteria which will be described in more details later on in this document.
In the system of our ineterst, the depth map generated from two or multiple camera views will be used as the depth source to find the position of objects in the scene when
overlaying virtual objects at different locations and depth levels in the real environment. For our research we decided to study the effect of using stereo vision in an AR 
system on two of the most important constraints mentioned above, which are {\it human factors} and {\it real-time interaction}. {\newline}
Human perception of depth can vary depending on the environment under different circumstances. Many studies have focused on the evaluation of human perception of depth within different
criteria. One of these areas of study is human perception of depth in augmented reality which has recently attracted more attention. These studies show that the viewer perception of depth
is inversely proportional to his distance from the object \cite{kru10,swa07,jer05,liv05}. In \cite{swa07} some experiments are designed to study and evaluate the human
perception of depth for an outdoor augmented reality application in urban settings. Since the scope of the problem they are interested in is similar to the initial problem domain we 
were motivated by in this research, we have set our criteria for the error in human peception of depth based on their published results and we will consider it as a reference for the 
evaluation of the depth results from stereo matching solutions. \newline
Providing real-time interaction in an AR system for the user requires the processing time and update rate of the whole system to keep up idealy with the standard video frame rate, between 24fps and 
30fps. However, studies show that in practice to build a reasonable interactive augmented world the processing rate should not be less than half of the video frame rate {\bf NOTE: Search for more vali
reference} \cite{spe}. There are different approaches to speed up a system. Acceleration of a system is possible in two ways:
\begin{enumerate}
\item Using more advanced technology and hardware
\item More complicated and efficient software design
\end{enumerate}
However, having access to advanced technology and better hardware is not always feasible and even the most advanced technology have some limitation to their memory space and computional capability whic
h may not meet the requirement for some real-time applications. 
Therefore, we have focused more on the second approach while designing our evaluation system which also look into the 3rd most important feature of
an AR system mentioned earlier, i.e, real-time user interaction. \newline In fact, one of the most important features that makes our evaluation unique and different from other works is that in order to
address the speed factor in augmented reality systems we have focused on certain regions rather than the whole image while evaluating the results.
We believe that in an outdoor augmented reality application there are certain regions in a scene which are more important to human sight and erroneous registeration of virtual and 
real object in those regions can be perceived and picked out easier by the users. Wrong results in these regions can result in poor performance of the system and possibly faulty interaction between 
the user and the augmented world. We have defined these regions to be the depth edges in the scene that have been expanded few pixels from each side. 
We believe that the depth edges, which will normally include object boundaries as well, are important depth cues for the user to perceive the depth of different objects in the scene. 
The reason we decided to extend the detected edges within a few pixels on each side is to also address occlusion and depth discontinuity. Finding correct depth values in these regions 
can lead to more accurate combination of virtual and real objects in the scene and therefore a more reasonable augmented world from the user point of view to interact with. \newline

In this research work, using our designed test bed we have evaluated two stereo matching algorithms as samples. These two algorithms are:
\begin{enumerate}
\item Semi-global stereo matching and mutual information by Hirschmuller \cite{hir08}
\item On building an accurate stereo matching system on graphics hardware \cite{mei11}
\end{enumerate}

The first algorithm by Hirschmuller has already been implemented in Open Source Computer Vision Library (OpenCV). Therefore, we have used its Opencv implementation that is 
called SGBM. On the other hand, there was no source code available for the second algorithm. So, we have used our own implementation of this solution in the evaluation process, both on CPU and GPU.

We have used Kitti stereo training dataset as our input for stereo pairs, since they are proper samples taken from outdoor scenes under different conditions and the ground truth disparity map
is also provided for each stereo pairs.



\bibliographystyle{plain}
\bibliography{reference} 
\end{document}
